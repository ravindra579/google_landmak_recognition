{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import keras\nimport numpy as np # linear algebra\nimport pandas as pd\nimport tensorflow as tf\nfrom cv2 import cv2\nimport random\n#from keras import bakend as k\nfrom PIL import Image\nfrom keras.utils.np_utils import to_categorical\nfrom keras.losses import binary_crossentropy\nfrom keras.objectives import mean_squared_error,mean_absolute_percentage_error\nimport keras\nfrom keras.callbacks import *\nimport matplotlib.pyplot as plt\nfrom keras.applications import MobileNetV2\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom keras.models import load_model\nfrom sklearn.model_selection import KFold,train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense,Dropout, Conv2D,Conv2DTranspose, BatchNormalization, Activation,AveragePooling2D,MaxPooling2D,Flatten,GlobalAveragePooling2D, Input, Concatenate, MaxPool2D, Add, UpSampling2D, LeakyReLU,ZeroPadding2D\nfrom keras.models import Model,Sequential\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau,LearningRateScheduler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=pd.read_csv(\"/kaggle/input/landmark-recognition-2020/train.csv\")\ndf_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"img\"]=df_train.id.str[0]+\"/\"+df_train.id.str[1]+\"/\"+df_train.id.str[2]+\"/\"+df_train.id+\".jpg\"\ndf_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"label\"]=df_train[\"landmark_id\"].values.astype(\"str\")\ndf_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop([\"landmark_id\"],axis=1,inplace=True)\ndf_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop([\"id\"],axis=1,inplace=True)\ndf_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.sample(frac=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop(df_train.tail(1000).img,inplace=True,axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop(df_train.tail(500000).index,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop(df_train.tail(69470).index,inplace=True)\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.img[df_train.index[1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.resize(1000000,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen=ImageDataGenerator(validation_split=0.25,samplewise_center=True, samplewise_std_normalization=True)\ntrain_generator=datagen.flow_from_dataframe(\ndataframe=df_train,\ndirectory=\"/kaggle/input/landmark-recognition-2020/train/\",\nx_col=\"img\",\ny_col=\"label\",\nsubset=\"training\",\nbatch_size=512,\nshuffle=True,\nclass_mode=\"categorical\",\ncolor_mode=\"rgb\",\ntarget_size=(224,224)\n)\nvalid_generator=datagen.flow_from_dataframe(\ndataframe=df_train,\ndirectory=\"/kaggle/input/landmark-recognition-2020/train/\",\nx_col=\"img\",\ny_col=\"label\",\nsubset=\"validation\",\nbatch_size=512,\nshuffle=True,\ncolor_mode=\"rgb\",\nclass_mode=\"categorical\",\ntarget_size=(224,224)\n)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dropout\nfrom keras.layers import Activation, BatchNormalization, Add, Reshape, DepthwiseConv2D\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.utils.vis_utils import plot_model\n\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def relu6(x):\n    return K.relu(x,max_value=6.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bottleneck(inputs, filters, kernel, t, s, r=False):\n    tchannel = K.int_shape(inputs)[1] * t\n    x=Conv2D(tchannel,(1,1),padding=\"same\",strides=(1,1))(inputs)\n    x=BatchNormalization()(x)\n    x=Activation(relu6)(x)\n    x = DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation(relu6)(x)\n    x = Conv2D(filters, (1, 1), strides=(1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n\n    if r:\n        x = Add()([x, inputs])\n\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def inverted_residual_block(inputs, filters, kernel, t, strides, n):    \n    x = bottleneck(inputs, filters, kernel, t, strides)\n    for i in range(1, n):\n        x = bottleneck(x, filters, kernel, t, 1, True)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mobilenet(inputshape,k):\n    inputs=Input(inputshape)\n    first_filter=32\n    x=Conv2D(32,(3,3),padding=\"same\",strides=(2,2))(inputs)\n    x=BatchNormalization()(x)\n    x=Activation(relu6)(x)\n    x = inverted_residual_block(x, 16, (3, 3), t=1, strides=1, n=1)\n    x = inverted_residual_block(x, 24, (3, 3), t=6, strides=2, n=2)\n    x = inverted_residual_block(x, 32, (3, 3), t=6, strides=2, n=3)\n    x = inverted_residual_block(x, 64, (3, 3), t=6, strides=2, n=4)\n    x = inverted_residual_block(x, 96, (3, 3), t=6, strides=1, n=3)\n    x = inverted_residual_block(x, 160, (3, 3), t=6, strides=2, n=3)\n    x = inverted_residual_block(x, 320, (3, 3), t=6,  strides=1, n=1)\n    last_filters=1280\n    x=Conv2D(1280,(1,1),padding=\"same\",strides=(1,1))(x)\n    x=BatchNormalization()(x)\n    x=Activation(relu6)(x)\n    x = GlobalAveragePooling2D()(x)\n    x = Reshape((1, 1, last_filters))(x)\n    x = Dropout(0.3, name='Dropout')(x)\n    x = Conv2D(k, (1, 1), padding='same')(x)\n    x = Activation('softmax', name='softmax')(x)\n    output = Reshape((k,))(x)\n    model = Model(inputs, output)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_l = Sequential()\nmodel_l.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(224,224,3)))\nmodel_l.add(BatchNormalization())\nmodel_l.add(Conv2D(32,kernel_size=3,activation='relu'))\nmodel_l.add(BatchNormalization())\nmodel_l.add(Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'))\nmodel_l.add(BatchNormalization())\nmodel_l.add(Dropout(0.4))\nmodel_l.add(Conv2D(64,kernel_size=3,activation='relu'))\nmodel_l.add(BatchNormalization())\nmodel_l.add(Conv2D(64,kernel_size=3,activation='relu'))\nmodel_l.add(BatchNormalization())\nmodel_l.add(Conv2D(64,kernel_size=5,strides=2,padding='same',activation='relu'))\nmodel_l.add(BatchNormalization())\nmodel_l.add(Dropout(0.4))\nmodel_l.add(Flatten())\nmodel_l.add(Dense(128, activation='relu'))\nmodel_l.add(BatchNormalization())\nmodel_l.add(Dropout(0.4))\nmodel_l.add(Dense(25753, activation='softmax'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=(32,32,3)))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(1026))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(81313, activation='softmax'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model_x=load_model(\"/kaggle/input/common-keras-pretrained-models/MobileNetV2.h5\")\n#model=mobilenet((224,224,3),81313)\nlearning_rate=0.00001\nlrr=ReduceLROnPlateau(monitor=\"accuracy\",patience=2,verbose=1,factor=0.5,min_lr=0.0000001)\nmodel_l.compile(optimizer=Adam(lr=learning_rate),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\nstep_size_train=train_generator.n//train_generator.batch_size\nstep_size_valid=valid_generator.n//valid_generator.batch_size\nhist=model_l.fit(train_generator,\n                    steps_per_epoch=step_size_train,\n                    validation_data=valid_generator,\n                    validation_steps=step_size_valid,\n               batch_size=512,\n                    epochs=1,\n              verbose=1,callbacks=[lrr]\n)\nmodel.save_weights(\"save_weights.h5\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}