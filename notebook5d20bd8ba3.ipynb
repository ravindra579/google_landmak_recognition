{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nimport numpy as np # linear algebra\nimport pandas as pd\nimport tensorflow as tf\nfrom cv2 import cv2\nimport random\n#from keras import bakend as k\nfrom PIL import Image\nfrom keras.utils.np_utils import to_categorical\nfrom keras.losses import binary_crossentropy\nfrom keras.objectives import mean_squared_error,mean_absolute_percentage_error\nimport keras\nfrom keras.callbacks import *\nimport matplotlib.pyplot as plt\nfrom keras.applications import MobileNetV2\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom keras.models import load_model\nfrom sklearn.model_selection import KFold,train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense,Dropout, Conv2D,Conv2DTranspose, BatchNormalization, Activation,AveragePooling2D,MaxPooling2D,Flatten,GlobalAveragePooling2D, Input, Concatenate, MaxPool2D, Add, UpSampling2D, LeakyReLU,ZeroPadding2D\nfrom keras.models import Model,Sequential\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau,LearningRateScheduler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=pd.read_csv(\"/kaggle/input/landmark-recognition-2020/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"img\"]=df_train.id.str[0]+\"/\"+df_train.id.str[1]+\"/\"+df_train.id.str[2]+\"/\"+df_train.id+\".jpg\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"label\"]=df_train[\"landmark_id\"].values.astype(\"str\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)\ntrain_generator=datagen.flow_from_dataframe(\ndataframe=df_train,\ndirectory=\"/kaggle/input/landmark-recognition-2020/train/\",\nx_col=\"img\",\ny_col=\"label\",\nsubset=\"training\",\nbatch_size=32,\nshuffle=True,\nclass_mode=\"categorical\",\ncolor_mode=\"rgb\",\ntarget_size=(32,32)\n)\nvalid_generator=datagen.flow_from_dataframe(\ndataframe=df_train,\ndirectory=\"/kaggle/input/landmark-recognition-2020/train/\",\nx_col=\"img\",\ny_col=\"label\",\nsubset=\"validation\",\nbatch_size=32,\nshuffle=True,\ncolor_mode=\"rgb\",\nclass_mode=\"categorical\",\ntarget_size=(128,128)\n)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from random import choices, sample\nfrom collections import Counter\n\nfrom plotly import graph_objects as go\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import Sampler\nimport albumentations as A\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision.models as models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel_l=models.resnext50_32x4d(pretrained=True)\nfor param in model_l.parameters():\n    param.requires_grad = False\n    \nhead = nn.Sequential(\n    nn.Linear(1000, 512),\n    nn.ReLU(),\n    nn.Linear(512, 100),\n)\nmodel=nn.Sequential(\n    model_l,\n    head,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category_n=1\ncategory=0\noutput_layer_n=category_n+4\ndef conv(x,y,k,s):\n      x=Conv2D(y,kernel_size=k,strides=s,padding='same')(x)\n      x=BatchNormalization()(x)\n      x=LeakyReLU(alpha=0.1)(x)\n      return x\ndef conv1(a,b,c,d):\n      b=Conv2DTranspose(c,kernel_size=2,strides=2,padding='valid',use_bias=False)(b)\n      b=BatchNormalization()(b)\n      b=LeakyReLU(alpha=0.1)(b)\n      x=Concatenate()([a,b])\n      x=Conv2D(d,kernel_size=1,strides=1,padding='same')(x)\n      x=BatchNormalization()(x)\n      x=LeakyReLU(alpha=0.1)(x)\n      return x\ndef adding(a,b):\n     x=conv(a,b,3,1)\n     x=conv(x,b,3,1)\n     x=Add()([x,a])\n     return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(input_shape):\n     input_layer=Input(input_shape)\n     input_layer_1=AveragePooling2D(2)(input_layer)\n     input_layer_2=AveragePooling2D(2)(input_layer_1)\n     x_0=conv(input_layer,16,3,2)\n     concat1=Concatenate()([x_0,input_layer_1])\n     x_1=conv(concat1,32,3,2)\n     concat2=Concatenate()([x_1,input_layer_2])\n     x_2=conv(concat2,64,3,2)\n     x=conv(x_2,64,3,1)\n     x=adding(x,64)\n     x=adding(x,64)\n     x_3=conv(x,128,3,2)\n     x=conv(x_3,128,3,1)\n     x=adding(x,128)\n     x=adding(x,128)\n     x=adding(x,128)\n     x_4=conv(x,256,3,2)\n     x=conv(x_4,256,3,1)\n     x=adding(x,256)\n     x=adding(x,256)\n     x=adding(x,256)\n     x=adding(x,256)\n     x=adding(x,256)\n     x_5=conv(x,512,3,2)\n     x=conv(x_5,512,3,1)\n     x=adding(x,512)\n     x=adding(x,512)\n     x=adding(x,512)\n     x_1= conv(x_1, output_layer_n, 1, 1)\n     x_1 = conv1(x_1, x_2, output_layer_n, output_layer_n)\n     x_2= conv(x_2, output_layer_n, 1, 1)\n     x_2 = conv1(x_2, x_3, output_layer_n, output_layer_n)\n     x_1 = conv1(x_1, x_2, output_layer_n, output_layer_n)\n     x_3= conv(x_3, output_layer_n, 1, 1)\n     x_3 = conv1(x_3, x_4, output_layer_n, output_layer_n) \n     x_2 = conv1(x_2, x_3, output_layer_n, output_layer_n)\n     x_1 = conv1(x_1, x_2, output_layer_n, output_layer_n)\n     x_4= conv(x_4, output_layer_n, 1, 1)\n     x=conv(x, output_layer_n, 1, 1)\n     x= UpSampling2D(size=(2, 2))(x)\n     x = Concatenate()([x, x_4])\n     x=conv(x, output_layer_n, 3, 1)\n     x= UpSampling2D(size=(2, 2))(x)\n     x = Concatenate()([x, x_3])\n     x=conv(x, output_layer_n, 3, 1)\n     x= UpSampling2D(size=(2, 2))(x)\n     x = Concatenate()([x, x_2])\n     x=conv(x, output_layer_n, 3, 1)\n     x= UpSampling2D(size=(2, 2))(x) \n     x = Concatenate()([x, x_1])\n     x=Conv2D(output_layer_n, kernel_size=3, strides=1, padding=\"same\")(x)\n     out = Dense(81313,activation=\"softmax\")(x)\n     model=Model(input_layer,out)\n     return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=MobileNetV2(\n    input_shape=(224,224,3),\n    alpha=1.0,\n    include_top=False,\n    input_tensor=None,\n    pooling=None,\n    classes=81313,\n    classifier_activation=\"softmax\",\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=(32,32,3)))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(1026))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(81313, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#model_x=load_model(\"/kaggle/input/common-keras-pretrained-models/MobileNetV2.h5\")\n#model=create_model(input_shape=(128,128,3))\nlearning_rate=0.001\nlrr=ReduceLROnPlateau(monitor=\"accuracy\",patience=2,verbose=1,factor=0.5,min_lr=0.0000001)\nmodel.compile(optimizer=Adam(lr=learning_rate),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\nstep_size_train=train_generator.n//train_generator.batch_size\nstep_size_valid=valid_generator.n//valid_generator.batch_size\nhist=model.fit(train_generator,\n                    steps_per_epoch=step_size_train,\n                    validation_data=valid_generator,\n                    validation_steps=step_size_valid,\n                    epochs=1,\n              verbose=1,callbacks=[lrr]\n)\nmodel.save_weights(\"save_weights.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport os\nimport PIL","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=pd.read_csv(\"/kaggle/input/landmark-recognition-2020/train.csv\")\ntrain_df=pd.read_csv(\"/kaggle/input/landmark-recognition-2020/train.csv\")\ndf_train[\"img\"]=df_train.id.str[0]+\"/\"+df_train.id.str[1]+\"/\"+df_train.id.str[2]+\"/\"+df_train.id+\".jpg\"\ndf_train.drop([\"id\"],inplace=True,axis=1)\ndf_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print((train_df.keys))\nnumber=1580470","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def main():\n NUM_PUBLIC_TRAIN_IMAGES=1580470\n if number == NUM_PUBLIC_TRAIN_IMAGES:\n    save_submission()\n    return\n _,pred=predictions(df_train)\n save_submission(pred)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_submission(prediction=None):\n     if prediction is None:\n        shutil.copyfile(os.path.join(DATASET_DIR, 'sample_submission.csv'), 'submission.csv')\n        return\n     with open('submission.csv', 'w') as submission_csv:\n      csv_writer = csv.DictWriter(submission_csv, fieldnames=['id', 'landmarks'])\n      csv_writer.writeheader()\n      for image_id, prediction in predictions.items():\n       label = prediction['class']\n       score = prediction['score']\n       csv_writer.writerow({'id': image_id, 'landmarks': f'{label} {score}'})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predictions(df_t):\n    test_ids,test_embeddings=extract()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}